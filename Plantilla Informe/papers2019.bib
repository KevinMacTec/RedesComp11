@article{Tian2013,
author = {Tian, Yuanyuan and Balmin, Andrey and Corsten, SA},
journal = {Vldb},
keywords = {IBM},
pages = {193--204},
title = {{Giraph++: From “think like a vertex” to “think like a graph”}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:From+{\%}22+Think+Like+a+Vertex+{\%}22+to+{\%}22+Think+Like+a+Graph+{\%}22{\#}0{\%}5Cnhttp://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:From+?think+like+a+vertex?+to+?think+like+a+graph?{\%}230{\%}5Cnhttp://},
year = {2013}
}
@Inbook{Bonifati2018,
	author="Bonifati, Angela
	and Fletcher, George
	and Hidders, Jan
	and Iosup, Alexandru",
	editor="Fletcher, George
	and Hidders, Jan
	and Larriba-Pey, Josep Llu{\'i}s",
	title="A Survey of Benchmarks for Graph-Processing Systems",
	bookTitle="Graph Data Management: Fundamental Issues and Recent Developments",
	year="2018",
	publisher="Springer International Publishing",
	address="Cham",
	pages="163--186",
	abstract="Benchmarking is a process that informs the public about the capabilities of systems-under-test, focuses on expected and unexpected system-bottlenecks, and promises to facilitate system tuning and new systems designs. In this chapter, we survey benchmarking approaches for graph-processing systems. First, we describe the main features of a benchmark for graph-processing systems. Then, we systematically survey across these features a diverse set of benchmarks for RDF databases, benchmarks for graph databases, benchmarks for parallel and distributed graph-processing systems, and data-only benchmarks. We trace in our survey not only the important benchmarks, but also their innovative approaches and how their core ideas evolved from previous benchmarking approaches. Last, we identify ongoing and future research directions for benchmarking initiatives.",
	isbn="978-3-319-96193-4",
	doi="10.1007/978-3-319-96193-4_6",
	url="https://doi.org/10.1007/978-3-319-96193-4_6"
}


@article{Junghanns2018,
abstract = {We demonstrate Gradoop, an open source framework that combines and extends features of graph database systems with the benefits of distributed graph processing. Using a rich graph data model and powerful graph operators, users can declaratively express graph analytical programs for distributed execution without needing advanced programming experience or a deeper understanding of the underlying system. Visitors of the demo can declare graph analytical programs using the Gradoop operators and also visually experience two of our advanced operators: graph pattern matching and graph grouping. We provide real world and artificial social network data with up to 10 billion edges and allow running the programs either locally or on a remote research cluster to demonstrate scalability.},
author = {Junghanns, Martin and Kie{\ss}ling, Max and Teichmann, Niklas and G{\'{o}}mez, Kevin and Petermann, Andr{\'{e}} and Rahm, Erhard},
doi = {10.14778/3229863.3236246},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
number = {12},
pages = {2006--2009},
title = {{Declarative and distributed graph analytics with GRADOOP}},
url = {http://dl.acm.org/citation.cfm?doid=3229863.3275583},
volume = {11},
year = {2018}
}
@article{Bassiliades2015,
abstract = {Thanks to the proliferation of Online Social Networks (OSNs) and Linked Data, graph data have been constantly increasing, reaching massive scales and complexity. Thus, tools to store and manage such data efficiently are absolutely essential. To address this problem, various technologies have been employed, such as relational, object and graph databases. In this paper we present a benchmark that evaluates graph databases with a set of workloads, inspired from OSN mining use case scenarios. In addition to standard network operations, the paper focuses on the problem of community detection and we propose the adaptation of the Louvain method on top of graph databases. The paper reports a comprehensive comparative evaluation between three popular graph databases, Titan, OrientDB and Neo4j. Our experimental results show that in the current development status Neo4j is the most efficient graph database for most of the employed workloads, while Titan handles better single insertion operations.},
author = {Bassiliades, Nick and Ivanovic, Mirjana and Kon-Popovska, Margita and Manolopoulos, Yannis and Palpanas, Themis and Trajcevski, Goce and Vakali, Athena},
doi = {10.1007/978-3-319-10518-5},
isbn = {9783319105178},
issn = {21945357},
journal = {Advances in Intelligent Systems and Computing},
pages = {3--14},
title = {{Benchmarking Graph Databases on the Problem of Community Detection}},
volume = {312},
year = {2015}
}
@article{Wittern2018,
abstract = {GraphQL is a query language and thereupon-based paradigm for implementing web Application Programming Interfaces (APIs) for client-server interactions. Using GraphQL, clients define precise, nested data-requirements in typed queries, which are resolved by servers against (possibly multiple) backend systems, like databases, object storages, or other APIs. Clients receive only the data they care about, in a single request. However, providers of existing REST(-like) APIs need to implement additional GraphQL interfaces to enable these advantages. We here assess the feasibility of automatically generating GraphQL wrappers for existing REST(-like) APIs. A wrapper, upon receiving GraphQL queries, translates them to requests against the target API. We discuss the challenges for creating such wrappers, including dealing with data sanitation, authentication, or handling nested queries. We furthermore present a prototypical implementation of OASGraph. OASGraph takes as input an OpenAPI Specification (OAS) describing an existing REST(-like) web API and generates a GraphQL wrapper for it. We evaluate OASGraph by running it, as well as an existing open source alternative, against 959 publicly available OAS. This experiment shows that OASGraph outperforms the existing alternative and is able to create a GraphQL wrapper for 89.5{\%} of the APIs -- however, with limitations in many cases. A subsequent analysis of errors and warnings produced by OASGraph shows that missing or ambiguous information in the assessed OAS hinders creating complete wrappers. Finally, we present a use case of the IBM Watson Language Translator API that shows that small changes to an OAS allow OASGraph to generate more idiomatic and more expressive GraphQL wrappers.},
archivePrefix = {arXiv},
arxivId = {arXiv:1809.08319v1},
author = {Wittern, Erik and Cha, Alan and Laredo, Jim A.},
doi = {10.1007/978-3-319-91662-0_5},
eprint = {arXiv:1809.08319v1},
isbn = {9783319916613},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {65--83},
title = {{Generating GraphQL-wrappers for REST(-like) APIs}},
volume = {10845 LNCS},
year = {2018}
}
@article{Ahmad2013,
abstract = {With the advent of cloud computing, many applications have embraced the ensuing paradigm shift towards modern distributed key-value data stores, like HBase, in order to benefit from the elastic scalability on offer. However, many applications still hesitate to make the leap from the traditional relational database model simply because they cannot compromise on the standard transactional guarantees of atomicity, isolation, and durability. To get the best of both worlds, one option is to integrate an independent transaction management component with a distributed key-value store. In this paper, we discuss the implications of this approach for durability. In particular, if the transaction manager provides durability (e.g., through logging), then we can relax durability constraints in the key-value store. However, if a component fails (e.g., a client or a key-value server), then we need a coordinated recovery procedure to ensure that commits are persisted correctly. In our research, we integrate an independent transaction manager with HBase. Our main contribution is a failure recovery middleware for the integrated system, which tracks the progress of each commit as it is flushed down by the client and persisted within HBase, so that we can recover reliably from failures. During recovery, commits that were interrupted by the failure are replayed from the transaction management log. Importantly, the recovery process does not interrupt transaction processing on the available servers. Using a benchmark, we evaluate the impact of component failure, and subsequent recovery, on application performance. {\textcopyright} IFIP International Federation for Information Processing 2013.},
author = {Ahmad, Muhammad Yousuf and Kemme, Bettina and Brondino, Ivan and Patin{\~{o}}-Mart{\'{i}}nez, Marta and Jiḿenez-Peris, Ricardo},
doi = {10.1007/978-3-642-45065-5_14},
isbn = {9783642450648},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Cloud computing,Failure recovery,Fault tolerance,Key-value store,OLTP,Transaction processing},
pages = {267--286},
title = {{Transactional failure recovery for a distributed key-value store}},
volume = {8275 LNCS},
year = {2013}
}
@article{Dey2014,
abstract = {Many cloud systems provide data stores with limited fea-tures, especially they may not provide transactions, or else restrict transactions to a single item. We propose a approach that gives multi-item transactions across heterogeneous data stores, using only a minimal set of features from each store such as single item consistency, conditional update, and the ability to include extra metadata within a value. We offer a client-coordinated transaction protocol that does not need a central coordinating infrastructure. A prototype implemen-tation has been built as a Java library and measured with an extension of YCSB benchmark to exercise multi-item trans-actions.},
author = {Dey, Akon and Fekete, Alan and R{\"{o}}hm, Uwe},
doi = {10.14778/2536274.2536331},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
number = {12},
pages = {1434--1439},
title = {{Scalable transactions across heterogeneous NoSQL key-value data stores}},
volume = {6},
year = {2014}
}
@article{Huang2016,
abstract = {{\textcopyright} 2015 IEEE. The data partition balance impacts the performance of NoSQL systems significantly. Most of the P2P NoSQL systems use consistent hashing to partition data automatically. Currently, these systems use random virtual nodes or manual configuration to divide the consistent hashing ring, which may cause load imbalance and degrade the performance. The problem is pronounced especially for heterogeneous clusters. In this paper, we focus on the partition strategy of consistent hashing ring and propose a data partition quantified criterion. When initializing a cluster, we convert the problem to an optimization problem to find the most even partitioning result. Experiments on Cassandra and Voldemort show these methods are better than current implementations. Besides, the algorithms are very efficient even for heterogeneous clusters.},
author = {Huang, Xiangdong and Wang, Jianmin and Zhong, Yu and Yu, Philip S.},
doi = {10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.182},
isbn = {9781467372114},
journal = {Proceedings - 2015 IEEE 12th International Conference on Ubiquitous Intelligence and Computing, 2015 IEEE 12th International Conference on Advanced and Trusted Computing, 2015 IEEE 15th International Conference on Scalable Computing and Communications, 20},
keywords = {Cassandra,DHT,Data Partition},
pages = {962--969},
publisher = {IEEE},
title = {{Optimizing data partition for NoSQL cluster}},
year = {2016}
}
@article{Hecht2011,
abstract = {Motivated by requirements of Web 2.0 applications, a plethora of non-relational databases raised in recent years. Since it is very difficult to choose a suitable database for a specific use case, this paper evaluates the underlying techniques of NoSQL databases considering their applicability for certain requirements. These systems are compared by their data models, query possibilities, concurrency controls, partitioning and replication opportunities.},
author = {Hecht, Robin and Jablonski, Stefan},
doi = {10.1109/CSC.2011.6138544},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hecht, Jablonski - 2011 - NoSQL evaluation A use case oriented survey.pdf:pdf},
isbn = {9781457716362},
journal = {Proceedings - 2011 International Conference on Cloud and Service Computing, CSC 2011},
keywords = {Column Family Stores,Document Stores,Evaluation,Graph Databases,Key Value Stores,NoSQL,Use Cases},
pages = {336--341},
title = {{NoSQL evaluation: A use case oriented survey}},
year = {2011}
}
@inproceedings{Sylvia2018,
abstract = {In today's era, organizations are developing applications which continuously and rapidly generates large amount of data. In this world of big data, NoSQL databases are rapidly becoming popular for storing information among organizations. Therefore, it is essential for an organization to choose a database which is compatible and efficient for their applications. To choose a correct data‐ base, it is essential to examine the performance of various databases under diverse workload conditions. In this paper, we are examining different document oriented databases on various workloads, so that we can categorize them according to application need. The evaluation has been performed on four NoSQL document oriented databases: MongoDB, ArangoDB, Elastic search and OrientDB with the help of Yahoo Cloud Service Benchmark (YCSB), which is a popular benchmark tool. Comparison is done in two parts: In the first part, all the databases are compared for single thread on the basis of throughput and runtime. Here, Mongo DB shows better results with highest throughput and lowest runtime among all the databases. In the second part, a thorough analysis is done in which MongoDB and ArangoDB are compared for some threads on different workloads. Here also, Mongo DB outperforms ArangoDB with a high percentage.},
author = {Sylvia, Martha L. and Terhaar, Mary F. and Wilson, Marisa L.},
booktitle = {Clinical Analytics and Data Management for the DNP},
doi = {10.1891/9780826142788.0020},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sylvia, Terhaar, Wilson - 2018 - Document Oriented NoSQL Databases An Empirical Study.pdf:pdf},
isbn = {9789811085277},
keywords = {arangodb,big data,document oriented databases,elastic search,mongodb,orientdb,ycsb},
pages = {126--136},
title = {{Document Oriented NoSQL Databases: An Empirical Study}},
year = {2018}
}
@article{Lourenco2015,
abstract = {{\textcopyright} 2015, Louren{\c{c}}o et al.; licensee Springer. For over forty years, relational databases have been the leading model for data storage, retrieval and management. However, due to increasing needs for scalability and performance, alternative systems have emerged, namely NoSQL technology. The rising interest in NoSQL technology, as well as the growth in the number of use case scenarios, over the last few years resulted in an increasing number of evaluations and comparisons among competing NoSQL technologies. While most research work mostly focuses on performance evaluation using standard benchmarks, it is important to notice that the architecture of real world systems is not only driven by performance requirements, but has to comprehensively include many other quality attribute requirements. Software quality attributes form the basis from which software engineers and architects develop software and make design decisions. Yet, there has been no quality attribute focused survey or classification of NoSQL databases where databases are compared with regards to their suitability for quality attributes common on the design of enterprise systems. To fill this gap, and aid software engineers and architects, in this article, we survey and create a concise and up-to-date comparison of NoSQL engines, identifying their most beneficial use case scenarios from the software engineer point of view and the quality attributes that each of them is most suited to.},
author = {Louren{\c{c}}o, Jo{\~{a}}o Ricardo and Cabral, Bruno and Carreiro, Paulo and Vieira, Marco and Bernardino, Jorge},
doi = {10.1186/s40537-015-0025-0},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Louren{\c{c}}o et al. - 2015 - Choosing the right NoSQL database for the job a quality attribute evaluation.pdf:pdf},
issn = {21961115},
journal = {Journal of Big Data},
keywords = {Columnar,Document store,Graph,Key-value,NoSQL databases,Quality attributes,Software architecture,Software engineering},
number = {1},
pages = {1--26},
publisher = {Journal of Big Data},
title = {{Choosing the right NoSQL database for the job: a quality attribute evaluation}},
url = {http://dx.doi.org/10.1186/s40537-015-0025-0},
volume = {2},
year = {2015}
}
@inproceedings{Fraczek2017,
abstract = {This paper presents comparative analysis of relational and non-relational databases. For the purposes of this paper simple social- media web application was created. The application supports three types of databases: SQL (it was tested with PostgreSQL), MongoDB and Apache Cassandra. For each database the applied data model was described. The aim of the analysis was to compare the performance of these selected databases in the context of data reading and writing. Per- formance tests showed that MongoDB is the fastest when reading data and PostgreSQL is the fastest for writing. The test application is fully functional, however implementation occurred to be more challenging for Cassandra.},
author = {Fraczek, Konrad and B, Malgorzata Plechawska-wojcik},
doi = {10.1007/978-3-319-58274-0},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fraczek, Plechawska-Wojcik - 2017 - Comparative Analysis of Relational and Non-relational Databases in the Context of Performance in Web.pdf:pdf},
isbn = {978-3-319-58273-3},
keywords = {cassandra,mongodb,nosql,relational databases},
pages = {153--164},
title = {{Comparative Analysis of Relational and Non-relational Databases in the Context of Performance in Web Applications}},
url = {http://link.springer.com/10.1007/978-3-319-58274-0},
volume = {716},
year = {2017}
}
@article{Chickerur2016,
abstract = {{\textcopyright} 2015 IEEE.Database can accommodate a very large number of users on an on-demand basis. The main limitations with conventional relational database management systems (RDBMS) are that they are hard to scale with Data warehousing, Grid, Web 2.0 and Cloud applications, have non-linear query execution time, have unstable query plans and have static schema. Even though RDBMS's have provided database users with the best mix of simplicity, robustness, flexibility, performance, scalability and compatibility but they are not able to satisfy the present day users and applications for the reasons mentioned above. The next generation NonSQL (NoSQL) databases are mostly non-relational, distributed and horizontally scalable and are able to satisfy most of the needs of the present day applications. The main characteristics of these databases are schema-free, no join, non-relational, easy replication support, simple API and eventually consistent. The aim of this paper is to illustrate how a problem being solved using MySQL will perform when MongoDB is used on a Big data dataset. The results are encouraging and clearly showcase the comparisons made. Queries are executed on a big data airlines database using both MongoDB and MySQL. Select, update, delete and insert queries are executed and performance is evaluated.},
author = {Chickerur, Satyadhyan and Goudar, Anoop and Kinnerkar, Ankita},
doi = {10.1109/ASEA.2015.19},
file = {:home/lorenae/MEGA/fing/cursos/BDNR/2019/lab/proyectos/07433067.pdf:pdf},
isbn = {9781467398374},
journal = {Proceedings - 8th International Conference on Advanced Software Engineering and Its Applications, ASEA 2015},
keywords = {Big data,MongoDB,MySQL,NoSQL,Performance Comparison},
pages = {41--47},
publisher = {IEEE},
title = {{Comparison of Relational Database with Document-Oriented Database (MongoDB) for Big Data Applications}},
year = {2016}
}
@article{Sylvia2018a,
abstract = {Bibliotheken sind in einer priviligierten Situation: Sie verwalten riesige Mengen von Daten und Informationen. Data Science und Analytics-Methoden erm{\"{o}}glichen es Bibliotheken, den Inhalt, den sie verwalten, voll auszunutzen, um den Nutzern bessere Informationen, Suche und Empfehlungen zu bieten.},
author = {Sylvia, Martha L. and Terhaar, Mary F. and Wilson, Marisa L.},
doi = {10.1891/9780826142788.0020},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sylvia, Terhaar, Wilson - 2018 - An Insightful View on Security and Performance of NoSQL Databases.pdf:pdf},
isbn = {9789811085277},
journal = {Clinical Analytics and Data Management for the DNP},
keywords = {cassandra,mongo db,nosql,redis,security in nosql},
pages = {643--653},
title = {{An Insightful View on Security and Performance of NoSQL Databases}},
year = {2018}
}
@article{Rosselli2019,
author = {Rosselli, Marten and Niemann, Raik and Ivanov, Todor and Tolle, Karsten},
doi = {10.1007/978-3-319-77525-8_100028},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2019 - Benchmarking the Availability and Fault Tolerance of Cassandra.pdf:pdf},
isbn = {9783319497488},
journal = {Encyclopedia of Big Data Technologies},
pages = {220--220},
title = {{Benchmarking the Availability and Fault Tolerance of Cassandra Marten}},
volume = {2},
year = {2019}
}
@article{Truica2015,
abstract = {NoSQL databases are becoming increasingly popular as more developers seek new ways for storing information. The popularity of these databases has risen due to their flexibility and scalability needed in domains like Big Data and Cloud Computing. This paper examines asynchronous replication, one of the key features for a scalable and flexible system. Three of the most popular Document-Oriented Databases, MongoDB, CouchDB, and Couchbase, are examined. For testing, the execution time for CRUD operations for a single database instance and for a distributed environment with two nodes is taken into account and the results are compared with tests outcomes obtained for three relational database management systems: Microsoft SQL Server, MySQL, and PostgreSQL.},
archivePrefix = {arXiv},
arxivId = {arXiv:1806.04761v1},
author = {Truica, Ciprian Octavian and Radulescu, Florin and Boicea, Alexandru and Bucur, Ion},
doi = {10.1109/CSCS.2015.32},
eprint = {arXiv:1806.04761v1},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Truica et al. - 2015 - Performance evaluation for CRUD operations in asynchronously replicated document oriented database.pdf:pdf},
isbn = {9781479917792},
journal = {Proceedings - 2015 20th International Conference on Control Systems and Computer Science, CSCS 2015},
keywords = {Asynchronous replication,CRUD operations,CouchDB,Couchbase,Execution time,MongoDB,NoSQL},
pages = {191--196},
title = {{Performance evaluation for CRUD operations in asynchronously replicated document oriented database}},
year = {2015}
}
@article{Shah2014,
abstract = {We present a framework and methodology to benchmark NoSQL stores for large scale model persistence. NoSQL technologies potentially improve performance of some applications and provide schemaless data-structures, so are particularly suited to persisting large and heterogeneous models. Recent studies consider only a narrow set of NoSQL stores for large scale modelling. Benchmarking many technologies requires substantial effort due to the disparate interface each store provides. Our experiments compare a broad range of NoSQL stores in terms of processor time and disc space used. The framework and methodology is evaluated through a case study that involves persisting large reverse-engineered models of open source projects. The results give tool engineers and practitioners a basis for selecting a store to persist large models.},
author = {Shah, Seyyed M. and Wei, Ran and Kolovos, Dimitrios S. and Rose, Louis M. and Paige, Richard F. and Barmpis, Konstantinos},
doi = {10.1007/978-3-319-11653-2_36},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shah et al. - 2014 - A Framework to Benchmark NoSQL Data Stores for Large-Scale Model Persistence.pdf:pdf},
pages = {586--601},
title = {{A Framework to Benchmark NoSQL Data Stores for Large-Scale Model Persistence}},
year = {2014}
}
@article{Beynon-Dames2015,
abstract = {Selecting the appropriate data management infrastructure is still a hard task for the designers of mobile applications with large volumes of data. Considering NoSQL needs for such applications, this paper demonstrates how the physical implementation of the database may impact query performance. Specifically, we consider the needs of mobile users that involve constant spatial data traffic, such as querying for points of interest, map visualization, zooming and panning, routing and location tracking. We define a workload and process such queries over three types of databases: relational, document-based and graph-based. Our evaluation shows that a fair comparison requires specific workloads for each mobile feature, but that is not possible using the industry's standard benchmark tools. Overall, the paper shows that physical design must evolve to take advantage of the performance of NoSQL databases while keeping data consistency and integrity.},
author = {Beynon-Dames, Paul},
doi = {10.1016/0952-1976(96)84165-0},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Beynon-Dames - 1996 - Comparative Performance Evaluation of Relational and NoSQL Databases for Spatial and Mobile Applications.pdf:pdf},
isbn = {9783319228495},
issn = {09521976},
journal = {Engineering Applications of Artificial Intelligence},
keywords = {big data,nosql,performance,spatial databases},
number = {5},
pages = {575},
title = {{Comparative Performance Evaluation of Relational and NoSQL Databases for Spatial and Mobile Applications}},
volume = {9},
year = {2015}
}
@article{Pirzadeh2012,
abstract = {Recently there has been a considerable increase in the number of different Key-Value stores, for supporting data storage and applications on the cloud environment. While all these No-SQL solutions try to offer highly available and scalable services on the cloud, they are significantly different with each other in terms of the architecture and types of the applications, they try to support. Considering three widely-used such systems: Cassandra, HBase and Voldemort, in this paper we compare them in terms of their support for different types of query workloads. We are mainly focused on the range queries. Unlike HBase and Cassandra that have built-in support for range queries, Voldemort does not support this type of queries via its available API. For this matter, practical techniques are presented on top of Voldemort to support range queries. Our performance evaluation is based on mixed query workloads, in the sense that they contain a combination of short and long range queries, beside other types of typical queries on key-value stores such as lookup and update. We show that there are trade-offs in the performance of the selected system and scheme, and the types of the query workloads that can be processed efficiently.},
author = {Pirzadeh, Pouria and Tatemura, Junichi and Po, Oliver and Hacıg{\"{u}}m{\"{u}}ş, Hakan},
doi = {10.1007/s10723-012-9214-7},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pirzadeh et al. - 2012 - Performance Evaluation of Range Queries in Key Value Stores.pdf:pdf},
issn = {15707873},
journal = {Journal of Grid Computing},
keywords = {Key-value store,Performance study,Range index,Range query},
number = {1},
pages = {109--132},
title = {{Performance Evaluation of Range Queries in Key Value Stores}},
volume = {10},
year = {2012}
}
@inproceedings{Satapathy2017,
abstract = {Sartaj Kanwar, Nimita Mangal, Rajdeep Niyogi (2017) Event Detection Over Twitter Social Media. In: Mandal J., Satapathy S., Sanyal M., Bhateja V. (eds) Proceedings of the First International Conference on Intelligent Computing and Communication. Advances in Intelligent Systems and Computing, vol 458. Springer, Singapore},
author = {Satapathy, Suresh Chandra and {Kamakshi Prasad}, V. and {Padmaja Rani}, B. and Udgata, Siba K. and Raju, K. Srujan},
booktitle = {Advances in Intelligent Systems and Computing},
doi = {10.1007/978-981-10-2471-9},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Satapathy et al. - 2017 - Proceedings of the First International Conference on Computational Intelligence and Informatics ICCII 2016.pdf:pdf},
isbn = {9789811024702},
issn = {21945357},
keywords = {mysql},
title = {{Proceedings of the First International Conference on Computational Intelligence and Informatics: ICCII 2016}},
volume = {507},
year = {2017}
}
@article{Abramova2014,
abstract = {NoSQL data stores are widely used to store and retrieve possibly large amounts of data, typically in a key-value format. There are many NoSQL types with different performances, and thus it is important to compare them in terms of performance and verify how the performance is related to the database type. In this paper, we evaluate five most popular NoSQL databases: Cassandra, HBase, MongoDB, OrientDB and Redis. We compare those databases in terms of query performance, based on reads and updates, taking into consideration the typical workloads, as represented by the Yahoo! Cloud Serving Benchmark. This comparison allows users to choose the most appropriate database according to the specific mechanisms and application needs.},
author = {Abramova, Veronika and Bernardino, Jorge and Furtado, Pedro},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abramova, Bernardino, Furtado - 2014 - Which NoSQL Database A Performance Overview.pdf:pdf},
journal = {Open Journal of Databases},
number = {2},
pages = {17--24},
title = {{Which NoSQL Database? A Performance Overview}},
url = {https://estudogeral.sib.uc.pt/bitstream/10316/27748/1/Which NoSQL Database.pdf},
volume = {1},
year = {2014}
}
@article{Gandini2014,
abstract = {{\textcopyright} 2017 IEEE. For over forty years, relational databases have been the leading model for data storage, retrieval and management. However, due to increasing needs for scalability and performance, alternative systems have emerged, namely NewSQL technology. NewSQL is a class of modern relational database management systems (RDBMS) that provide the same scalable performance of NoSQL systems for online transaction processing (OLTP) read-write workloads while still maintaining the ACID guarantees of a traditional database system. The rising interest in NewSQL technology, over the last few years resulted in an increasing number of evaluations and comparisons among competing NewSQL technologies. Some of the NewSQL databases currently used in various popular web applications are VoltDB, Google Spanner, MemSQL, SAP HANA, NuoDB, and TokuDB. This work is trying to comment on the various NewSQL database systems which describes benefits, characteristics, and classification of NewSQL databases for online transaction processing (OLTP) for Big data management. It also provides the list of popular NewSQL databases in categorized tables. This dissertation work mainly covers evaluation comparison between four NewSQL databases: NuoDB, VoltDB, MemSQL, and Cockroach DB on the basis of various parameters like read latency, write latency, update latency, and execution time. The experiments do not cover only performance (latency and execution time) but also focus on ease of use and flexibility of the used NewSQL databases.},
author = {Gandini, Andrea and Gribaudo, Marco and Knottenbelt, William J. and Osman, Rasha and Piazzolla, Pietro},
doi = {10.1007/978-3-319-10885-8_2},
file = {:home/lorenae/MEGA/fing/cursos/BDNR/2019/lab/proyectos/Gandini2014{\_}Chapter{\_}PerformanceEvaluationOfNoSQLDa.pdf:pdf},
isbn = {9783319108841},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {16--29},
title = {{Performance evaluation of NoSQL databases}},
volume = {8721 LNCS},
year = {2014}
}
@article{Hajoui2015,
abstract = {{\textcopyright} 2005 - 2015 JATIT {\&} LLS. All rights reserved.Big data usually includes data sets with sizes beyond the ability of commonly used software tools to capture, curate, manage, and process data within a tolerable elapsed time[1].Big data "size" is a constantly moving target, as of 2012 ranging from a few dozen terabytes to many petabytes of data. Big data is a set of techniques and technologies that require new forms of integration to uncover large hidden values from large datasets that are diverse, complex, and of a massive scale [2]. Currently, there are a hundred solutions to the problem of Big Data that can be classified into three categories: NoSQL databases, NewSQL and Search-based systems. One of the major problems often mentioned is the heterogeneity of the languages and the interfaces they offer to developers and users. Different platforms and languages have been proposed, and applications developed for one system require significant effort to be migrated to another one [3]. Our motivation to write this article is to make a comparative study of Big Data systems, this is our first step to design and implement concrete and effective solution to the interoperability problem between Big Data systems. However, this study will help the professionals in decision-making.},
author = {Hajoui, Omar and Dehbi, Rachid and Talea, Mohammed and Batouta, Zouhair Ibn},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hajoui et al. - 2015 - An advanced comparative study of the most promising NoSQL and NewSQL databases with a multi-criteria analysis met.pdf:pdf},
issn = {18173195},
journal = {Journal of Theoretical and Applied Information Technology},
keywords = {Big data analysis,Multi-criteria analysis method (ROC),NewSQL databases,NoSQL databases,NoSQL databases categories},
number = {3},
pages = {579--588},
title = {{An advanced comparative study of the most promising NoSQL and NewSQL databases with a multi-criteria analysis method}},
volume = {81},
year = {2015}
}
@article{Fung2018,
author = {Fung, Lim and Firdaus, Nurulhuda and Azmi, Mohd},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fung, Firdaus, Azmi - 2018 - Software Evolution A Review on Approaches in Handling Database Schema .pdf:pdf},
keywords = {approaches,change detection,database,database schema,laws of software evolution,software evolution},
number = {3},
pages = {11--20},
title = {{Software Evolution : A Review on Approaches in Handling Database Schema .}},
volume = {6},
year = {2018}
}
@article{Ai-Sakran2018,
abstract = {As one of the largest-technology penetrations, Internet of Things (IoT) has gained a considerable attention across both, research communities and industrial domains. IoT is a network of billions of connected devices that are capable of communicating over the Internet. In IoT, data is generated exponentially by different real-time applications (e.g., social network sites and sensor-based devices). The traditional relational database management technologies are inappropriate to deal with such new generation of data due to its limited processing speed, scalability issues, and limited storage capacity. The advent of Big Data requires new advanced technologies that are capable of handling (storing, retrieving and processing) large amount of unstructured data that IoT applications produce. Not Only SQL (NoSQL) databases emerged as a solution to overcome some limitations of the traditional relational database. Recently, many NoSQL databases have been announced (e.g., Cassandra, MongoDB, HBase, Apache Hadoop, Voldemort) to deal with tremendous amounts of unstructured data. These databases depend mainly on distributed algorithms for their work in the field of IoT. One of the most used distributed algorithms is Chord protocol. However, Chord algorithm is inefficient in some cases because of its way of handling messages transferred between connected devices. All the messages in Chord are passed clockwise along the Chord ring, which leads to send a huge number of redundant messages. Chord works by creating a lookup table for each node connected to the network, which generates huge number of tables that should be updated regularly with the routing information. This paper presents a proposal for implementing an enhanced version of the distributed Chord protocol using the most two popular NoSQL databases, namely: MongoDB and Cassandra. The new version of the Chord algorithm will be evaluated and compared to the current algorithm against their performance using the two databases. Moreover, the two databases will be compared regarding their performance in terms of database operations (reading, writing, updating and deleting) and the number of messages that are sent by the nodes. The home environment controlling IoT application will be simulated using SensibleThings distributed platform for simulating the implementation of the modified protocol and to compare between the performance of the two databases.},
author = {Ai-Sakran, Aya and Qattous, Hazem and Hijjawi, Mohammad},
doi = {10.1109/CSIT.2018.8486199},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ai-Sakran, Qattous, Hijjawi - 2018 - A proposed performance evaluation of NoSQL databases in the field of IoT.pdf:pdf},
isbn = {9781538641521},
journal = {2018 8th International Conference on Computer Science and Information Technology, CSIT 2018},
keywords = {BASE,Big Data,Chord protocol,Internet of Things (IoT),MongoDB,NoSQL,RDBMS},
pages = {32--37},
publisher = {IEEE},
title = {{A proposed performance evaluation of NoSQL databases in the field of IoT}},
year = {2018}
}
@article{Vicknair2012,
author = {Vicknair, Chad and Macias, Michael},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vicknair, Macias - 2012 - A Comparison of a Graph Database and Relational Database(2).pdf:pdf},
isbn = {9781450300643},
title = {{A Comparison of a Graph Database and Relational Database}},
url = {https://pdfs.semanticscholar.org/4a30/343f3230dddd96fd6f79547fef9407262dbf.pdf},
year = {2012}
}
@article{Tang2017,
abstract = {Recently NoSQL databases and their related technologies are developing rapidly and are widely applied in many scenarios with their BASE (Basic Availability, Soft state, Eventual consistency) features. At present, there are more than 225 kinds of NoSQL databases. However, the overwhelming amount and constantly updated versions of databases make it challenging for people to compare their performance and choose an appropriate one. This paper is trying to evaluate the performance of five NoSQL clusters (Redis, MongoDB, Couchbase, Cassandra, HBase) by using a measurement tool - YCSB (Yahoo! Cloud Serving Benchmark), explain the experimental results by analyzing each database's data model and mechanism, and provide advice to NoSQL developers and users.},
author = {Tang, Enqing and Fan, Yushun},
doi = {10.1109/CCBD.2016.030},
file = {:home/lorenae/MEGA/fing/cursos/BDNR/2019/lab/proyectos/07979888.pdf:pdf},
isbn = {9781509035557},
journal = {Proceedings - 2016 7th International Conference on Cloud Computing and Big Data, CCBD 2016},
keywords = {NoSQL cluster,NoSQL database,YCSB,performance comparison},
pages = {105--109},
title = {{Performance comparison between five NoSQL databases}},
year = {2017}
}
@article{Kabakus2017,
abstract = {The popularity of NoSQL databases has increased due to the need of (1) processing vast amount of data faster than the relational database management systems by taking the advantage of highly scalable architecture, (2) flexible (schema-free) data structure, and, (3) low latency and high performance. Despite that memory usage is not major criteria to evaluate performance of algorithms, since these databases serve the data from memory, their memory usages are also experimented alongside the time taken to complete each operation in the paper to reveal which one uses the memory most efficiently. Currently there exists over 225 NoSQL databases that provide different features and characteristics. So it is necessary to reveal which one provides better performance for different data operations. In this paper, we experiment the widely used in-memory databases to measure their performance in terms of (1) the time taken to complete operations, and (2) how efficiently they use memory during operations. As per the results reported in this paper, there is no database that provides the best performance for all data operations. It is also proved that even though a RDMS stores its data in memory, its overall performance is worse than NoSQL databases.},
author = {Kabakus, Abdullah Talha and Kara, Resul},
doi = {10.1016/j.jksuci.2016.06.007},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kabakus, Kara - 2017 - A performance evaluation of in-memory databases.pdf:pdf},
issn = {22131248},
journal = {Journal of King Saud University - Computer and Information Sciences},
keywords = {Database performance,In-memory databases,NoSQL databases},
number = {4},
pages = {520--525},
publisher = {King Saud University},
title = {{A performance evaluation of in-memory databases}},
url = {https://doi.org/10.1016/j.jksuci.2016.06.007},
volume = {29},
year = {2017}
}
@article{Mason2015,
abstract = {NoSQL databases are an important component of Big Data for storing and retrieving large vol- umes of data. Traditional Relational Database Management Systems (RDBMS) use the ACID theorem for data consistency, whereas NoSQL Databases use a non-transactional approach called BASE. RDBMS scale vertically and NoSQL Databases can scale both horizontally (sharding) and vertically. Four types of NoSQL databases are Document-oriented, Key-Value Pairs, Col- umn-oriented and Graph. Data modeling for Document-oriented databases is similar to data modeling for traditional RDBMS during the conceptual and logical modeling phases. However, for a physical data model, entities can be combined (denormalized) by using embedding. What was once called a foreign key in a traditional RDBMS is now called a reference in a Document- oriented NoSQL database.},
author = {Mason, Robert T},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mason - 2015 - NoSQL Databases and Data Modeling Techniques for a Document-oriented NoSQL Database.pdf:pdf},
journal = {Proceedings of Informing Science {\&} IT Education Conference (InSITE)},
keywords = {Database Technologies,NoSQL Data Modeling,NoSQL Databases,database technologies,nosql data modeling,nosql databases},
number = {4},
pages = {259--268},
title = {{NoSQL Databases and Data Modeling Techniques for a Document-oriented NoSQL Database}},
volume = {3},
year = {2015}
}
@article{Swaminathan2016,
abstract = {NoSQL databases are rapidly becoming the customary data platform for big data applications. These databases are emerging as a gateway for alternative approaches outside traditional relational databases and are characterized by efficient horizontal scalability, schema-less approach to data modeling, high performance data access, and limited querying capabilities. The lack of transactional semantics among NoSQL databases has made the choice of a particular consistency model dependent on the application. Therefore, it is essential to examine methodically, and in detail, the performance of various databases under diverse workload conditions. Three of the most commonly used NoSQL databases: MongoDB, Cassandra and HBase are evaluated using the Yahoo Cloud Service Bench-mark, a popular benchmark tool. The horizontal scalability of the three systems under different workload conditions and varying dataset sizes is captured. A benchmark suite which summarizes the results of the evaluation is presented.},
author = {Swaminathan, Surya Narayanan and Elmasri, Ramez},
doi = {10.1109/BigDataCongress.2016.49},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Swaminathan, Elmasri - 2016 - Quantitative analysis of scalable NoSQL databases.pdf:pdf},
isbn = {9781509026227},
journal = {Proceedings - 2016 IEEE International Congress on Big Data, BigData Congress 2016},
keywords = {Cassandra,Database Benchmark,HBase,MongoDB,NoSQL,YCSB},
pages = {323--326},
publisher = {IEEE},
title = {{Quantitative analysis of scalable NoSQL databases}},
year = {2016}
}
@article{Gudivada2014,
abstract = {With the development of the Internet and cloud computing, there need databases to be able to store and process big data effectively, demand for high-performance when reading and writing, so the traditional relational database is facing many new challenges. Especially in large scale and high-concurrency applications, such as search engines and SNS, using the relational database to store and query dynamic user data has appeared to be inadequate. In this case, NoSQL database created. This paper describes the background, basic characteristics, data model of NoSQL. In addition, this paper classifies NoSQL databases according to the CAP theorem. Finally, the mainstream NoSQL databases are separately described in detail, and extract some properties to help enterprises to choose NoSQL.},
author = {Gudivada, Venkat N. and Rao, Dhana and Raghavan, Vijay V.},
doi = {10.1109/SERVICES.2014.42},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gudivada, Rao, Raghavan - 2014 - NoSQL Systems for Big Data Management.pdf:pdf},
isbn = {978-1-4799-5069-0},
journal = {2014 IEEE World Congress on Services},
keywords = {-data models,big data,databases,document databases,graph,native xml databases,newsql,nosql},
pages = {190--197},
title = {{NoSQL Systems for Big Data Management}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6903264},
year = {2014}
}
@article{Gujral2018,
abstract = {{\textcopyright} 2018 IEEE. The usage and popularity of NoSQL databases have sharply risen over the past decade due to their ability to handle a huge amount of data by employing scalable architecture, high availability and better performance than traditional relational database systems (RDBMS). In addition to reporting dynamics in NoSQL-database world, this paper focuses on presenting results from the perspective of developers. Stack Overflow provides a comprehensive technical niche with about 15 million technical questions, 8.1 million users and 25 million answers. In this paper, we aim to study variation in yearly trends of 20 NoSQL databases. To reveal the interest of the programmers we have investigated questions-asked and presented an unbiased Normal Interest Score by employing three parameters, first, the number of questions asked, second, mean views on a question and third, the mean score on a question. MongoDB, Cassandra, Redis, and Neo4j emerged as most popular databases in their respective families while NIS of all four of them is decreasing 2015 onwards. Additionally, we have also discussed how real-world events like publications, open-sourcing, mention in critical bills, version-release, acquiring ventures etc affect the interest corresponding to NoSQL databases over Stack Overflow. Results of this work will help database developers, database administrators for database selection, upgradation and maintenance.},
author = {Gujral, Harshit and Sharma, Abhinav and Kaur, Parmeet},
doi = {10.1109/IC3.2018.8530582},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gujral, Sharma, Kaur - 2018 - Empirical Investigation of Trends in NoSQL-Based Big-Data Solutions in the Last Decade.pdf:pdf},
isbn = {9781538668351},
journal = {2018 11th International Conference on Contemporary Computing, IC3 2018},
keywords = {Big Data,Cassandra,Database,MongoDB,NoSQL,Stack Overflow},
pages = {4--6},
title = {{Empirical Investigation of Trends in NoSQL-Based Big-Data Solutions in the Last Decade}},
year = {2018}
}
@article{Sharma2012,
abstract = {{\{}NoSQL{\}} ($\backslash$nNot only {\{}SQL){\}} is a dat$\backslash$nabase used to store large amount$\backslash$ns$\backslash$nof data. {\{}NoSQL{\}} databases are distributed,$\backslash$nnon$\backslash$n-$\backslash$nrelational, open source and are horizontally scalable (in linear way). {\{}NoSQL{\}} does not follow property o$\backslash$nf {\{}ACID{\}} as we$\backslash$nfollow in {\{}SQL.{\}} I$\backslash$nn this research paper$\backslash$n,$\backslash$nwe are sur$\backslash$nvey$\backslash$ning abou$\backslash$nt$\backslash$n{\{}NoSQL{\}},$\backslash$nits$\backslash$nbackground,$\backslash$nfundamentals like {\{}ACID{\}}, {\{}BASE{\}}$\backslash$nand {\{}CAP{\}} theorem. Also on the basis of {\{}CAP{\}} theorem$\backslash$n,$\backslash$nstudy$\backslash$nis carried out$\backslash$nabout the various types of {\{}NoSQL{\}} data stores$\backslash$nwith their examples$\backslash$n,$\backslash$ncharacteristics,$\backslash$nand$\backslash$npros and cons of {\{}NoSQL.{\}}},
author = {Sharma, Vatika and Dave, Meenu},
file = {:home/lorenae/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sharma, Dave - 2012 - SQL and NoSQL Databases.pdf:pdf},
issn = {2277 128X},
journal = {International Journal of Advanced Research in Computer Science and Software Engineering},
keywords = {acid,base,cap,curd,nosql,sql},
number = {8},
pages = {20--27},
title = {{SQL and NoSQL Databases}},
volume = {2},
year = {2012}
}
@inproceedings{Bugiotti2014,
abstract = {We propose a database design methodology for NoSQL systems. The approach is based on NoAM (NoSQL Abstract Model), a novel abstract data model for NoSQL databases, which exploits the commonalities of various No-SQL systems and is used to specify a system-independent representation of the application data. This intermediate representation can be then implemented in target NoSQL databases, taking into account their specific features. Overall, the methodology aims at supporting scalability, performance, and consistency, as needed by next-generation web applications.},
author = {Bugiotti, Francesca and Cabibbo, Luca and Atzeni, Paolo and Torlone, Riccardo},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
file = {:home/lorenae/MEGA/fing/cursos/BDNR/2019/lab/proyectos/{\_}{\_}noam-er2014.pdf:pdf},
isbn = {9783319122052},
issn = {16113349},
pages = {223--231},
publisher = {Springer Verlag},
title = {{Database design for NoSQL systems}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84910601072{\&}partnerID=tZOtx3y1},
volume = {8824},
year = {2014}
}
